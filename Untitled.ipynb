{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f287e8-5077-42e1-ad3e-6e0914b24caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import dirichlet, poisson\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from scipy.special import logsumexp\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3a1d6-3447-408d-a03a-e2145f99b055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0b0086-32a3-4478-8207-9ed293103d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensembl_trx = data.ensembl_trx()\n",
    "#pickle.dump(ensembl_trx, open('data/ensembl_trx.pkl', 'wb'))\n",
    "ensembl_trx = pickle.load(open('ensembl_trx.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a28dce7-cc5b-4042-85f2-29eb05d29513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trx_orfs = data.trx_orfs(ensembl_trx)\n",
    "#pickle.dump(trx_orfs, open('data/trx_orfs.pkl', 'wb'))\n",
    "trx_orfs = pickle.load(open('trx_orfs.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6460cb1c-b311-4a91-9919-a9b200634d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 206497/206497 [00:11<00:00, 18433.94it/s]\n"
     ]
    }
   ],
   "source": [
    "for trx, attrs in tqdm(ensembl_trx.items()):\n",
    "    for orf, info in trx_orfs[trx].items():\n",
    "        if orf.startswith('ENSP'):\n",
    "            zero_arr = np.zeros(len(ensembl_trx[trx]['sequence']))\n",
    "            start, stop = info['start'], info['stop']\n",
    "            zero_arr[start:stop] = 1\n",
    "            ensembl_trx[trx]['target'] = zero_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c827b4-5a15-4122-aaaa-8b6db87db8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef446efb-f173-4510-ba70-4dd6f9748ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce9d5a6f-90f6-4d2a-a498-209a9c59b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def base_to_index(base):\n",
    "    return {'A': 0, 'C': 1, 'G': 2, 'T': 3}[base]\n",
    "\n",
    "def sequence_to_indices(sequence):\n",
    "    return np.array([base_to_index(b) for b in sequence])\n",
    "\n",
    "# Prior distributions\n",
    "def sample_r_prior():\n",
    "    return max(1, poisson.rvs(3, size=1)[0] % (MAX_STATES + 1))\n",
    "\n",
    "def sample_q_prior():\n",
    "    return poisson.rvs(1, size=1)[0] % (MAX_ORDER + 1)\n",
    "\n",
    "# Initialize model parameters\n",
    "def initialize_parameters(n_states, n_bases, q):\n",
    "    Lambda = dirichlet.rvs(np.ones(n_states), size=n_states)\n",
    "    P = dirichlet.rvs(np.ones(n_bases**(q+1)), size=n_states)\n",
    "    return Lambda, P\n",
    "\n",
    "def forward_multi(sequences, Lambda, P, q):\n",
    "    n_states, n_emissions = P.shape\n",
    "    total_log_likelihood = 0\n",
    "    all_forward = []\n",
    "    all_scale = []\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        n_obs = len(sequence)\n",
    "        F = np.zeros((n_states, n_obs))\n",
    "        scale = np.zeros(n_obs)\n",
    "        \n",
    "        # Initialize\n",
    "        initial_state = tuple(sequence[:q])\n",
    "        for i in range(n_states):\n",
    "            emission_index = np.ravel_multi_index(initial_state + (sequence[q],), (4,)*(q+1))\n",
    "            F[i, q-1] = P[i, emission_index] / n_states\n",
    "        scale[q-1] = np.sum(F[:, q-1])\n",
    "        F[:, q-1] /= scale[q-1]\n",
    "        \n",
    "        # Recurse\n",
    "        for t in range(q, n_obs):\n",
    "            state = tuple(sequence[t-q:t+1])\n",
    "            for j in range(n_states):\n",
    "                emission_index = np.ravel_multi_index(state, (4,)*(q+1))\n",
    "                F[j, t] = P[j, emission_index] * np.sum(F[:, t-1] * Lambda[:, j])\n",
    "            scale[t] = np.sum(F[:, t])\n",
    "            F[:, t] /= scale[t]\n",
    "        \n",
    "        total_log_likelihood += np.sum(np.log(scale))\n",
    "        all_forward.append(F)\n",
    "        all_scale.append(scale)\n",
    "    \n",
    "    return total_log_likelihood, all_forward, all_scale\n",
    "\n",
    "def backward_multi(sequences, Lambda, P, q, all_scale):\n",
    "    n_states, n_emissions = P.shape\n",
    "    all_backward = []\n",
    "    \n",
    "    for sequence, scale in zip(sequences, all_scale):\n",
    "        n_obs = len(sequence)\n",
    "        B = np.zeros((n_states, n_obs))\n",
    "        \n",
    "        # Initialize\n",
    "        B[:, -1] = 1 / scale[-1]\n",
    "        \n",
    "        # Recurse\n",
    "        for t in range(n_obs-2, q-2, -1):\n",
    "            state = tuple(sequence[t-q+1:t+2])\n",
    "            for i in range(n_states):\n",
    "                emission_index = np.ravel_multi_index(state, (4,)*(q+1))\n",
    "                B[i, t] = np.sum(B[:, t+1] * Lambda[i, :] * P[:, emission_index])\n",
    "            B[:, t] /= scale[t]\n",
    "        \n",
    "        all_backward.append(B)\n",
    "    \n",
    "    return all_backward\n",
    "\n",
    "def calculate_posterior_probs(all_forward, all_backward):\n",
    "    all_posterior_probs = []\n",
    "    for F, B in zip(all_forward, all_backward):\n",
    "        posterior_probs = F * B\n",
    "        posterior_probs /= np.sum(posterior_probs, axis=0)\n",
    "        all_posterior_probs.append(posterior_probs)\n",
    "    return all_posterior_probs\n",
    "\n",
    "def update_q_multi(sequences, r, q, Lambda, P):\n",
    "    log_probs = np.zeros(MAX_ORDER + 1)\n",
    "    for new_q in range(MAX_ORDER + 1):\n",
    "        new_P = dirichlet.rvs(np.ones(4**(new_q+1)), size=r)\n",
    "        log_probs[new_q], _, _ = forward_multi(sequences, Lambda, new_P, new_q)\n",
    "    \n",
    "    new_q = np.random.choice(MAX_ORDER + 1, p=np.exp(log_probs - logsumexp(log_probs)))\n",
    "    if new_q != q:\n",
    "        P = dirichlet.rvs(np.ones(4**(new_q+1)), size=r)\n",
    "    \n",
    "    return new_q, P\n",
    "\n",
    "def rjmcmc_r_multi(sequences, r, q, Lambda, P):\n",
    "    if np.random.random() < 0.5:  # Attempt birth\n",
    "        if r < MAX_STATES:\n",
    "            new_r = r + 1\n",
    "            new_Lambda = np.zeros((new_r, new_r))\n",
    "            new_Lambda[:r, :r] = Lambda\n",
    "            new_Lambda[r, :] = dirichlet.rvs(np.ones(new_r))\n",
    "            new_Lambda[:, r] = dirichlet.rvs(np.ones(new_r))\n",
    "            new_P = np.vstack((P, dirichlet.rvs(np.ones(4**(q+1)))))\n",
    "            \n",
    "            # Calculate acceptance probability\n",
    "            log_A, _, _ = forward_multi(sequences, new_Lambda, new_P, q)\n",
    "            log_A -= forward_multi(sequences, Lambda, P, q)[0]\n",
    "            log_A += np.log(new_r) - np.log(r + 1)  # Prior ratio and proposal ratio\n",
    "            \n",
    "            if np.log(np.random.random()) < log_A:\n",
    "                return new_r, new_Lambda, new_P\n",
    "    else:  # Attempt death\n",
    "        if r > 1:\n",
    "            new_r = r - 1\n",
    "            j = np.random.randint(r)\n",
    "            new_Lambda = np.delete(np.delete(Lambda, j, axis=0), j, axis=1)\n",
    "            new_P = np.delete(P, j, axis=0)\n",
    "            \n",
    "            # Calculate acceptance probability\n",
    "            log_A, _, _ = forward_multi(sequences, new_Lambda, new_P, q)\n",
    "            log_A -= forward_multi(sequences, Lambda, P, q)[0]\n",
    "            log_A += np.log(r) - np.log(new_r + 1)  # Prior ratio and proposal ratio\n",
    "            \n",
    "            if np.log(np.random.random()) < log_A:\n",
    "                return new_r, new_Lambda, new_P\n",
    "    \n",
    "    return r, Lambda, P\n",
    "\n",
    "def run_mcmc_multi(sequences, n_iter, n_burn_in, thin=1):\n",
    "    r = sample_r_prior()\n",
    "    q = sample_q_prior()\n",
    "    Lambda, P = initialize_parameters(r, 4, q)\n",
    "    \n",
    "    samples = []\n",
    "    for i in tqdm(range(n_iter + n_burn_in)):\n",
    "        # Update q and P\n",
    "        q, P = update_q_multi(sequences, r, q, Lambda, P)\n",
    "        \n",
    "        # Update Lambda\n",
    "        for j in range(r):\n",
    "            Lambda[j, :] = dirichlet.rvs(Lambda[j, :] + 1)\n",
    "        \n",
    "        # Reversible jump for r\n",
    "        r, Lambda, P = rjmcmc_r_multi(sequences, r, q, Lambda, P)\n",
    "        \n",
    "        # Store samples after burn-in period and apply thinning\n",
    "        if i >= n_burn_in and (i - n_burn_in) % thin == 0:\n",
    "            log_likelihood, all_forward, all_scale = forward_multi(sequences, Lambda, P, q)\n",
    "            all_backward = backward_multi(sequences, Lambda, P, q, all_scale)\n",
    "            all_posterior_probs = calculate_posterior_probs(all_forward, all_backward)\n",
    "            viterbi_paths = viterbi_multi(sequences, Lambda, P, q)\n",
    "            samples.append((r, q, Lambda.copy(), P.copy(), all_posterior_probs, viterbi_paths))\n",
    "    \n",
    "    return samples\n",
    "\n",
    "def viterbi_multi(sequences, Lambda, P, q):\n",
    "    segmentations = []\n",
    "    for sequence in sequences:\n",
    "        n_states, n_emissions = P.shape\n",
    "        n_obs = len(sequence)\n",
    "        V = np.zeros((n_states, n_obs))\n",
    "        path = np.zeros((n_states, n_obs), dtype=int)\n",
    "        \n",
    "        # Initialize\n",
    "        initial_state = tuple(sequence[:q])\n",
    "        for i in range(n_states):\n",
    "            emission_index = np.ravel_multi_index(initial_state + (sequence[q],), (4,)*(q+1))\n",
    "            V[i, q-1] = np.log(P[i, emission_index] / n_states)\n",
    "        \n",
    "        # Recurse\n",
    "        for t in range(q, n_obs):\n",
    "            state = tuple(sequence[t-q:t+1])\n",
    "            for j in range(n_states):\n",
    "                emission_index = np.ravel_multi_index(state, (4,)*(q+1))\n",
    "                prob = V[:, t-1] + np.log(Lambda[:, j]) + np.log(P[j, emission_index])\n",
    "                V[j, t] = np.max(prob)\n",
    "                path[j, t] = np.argmax(prob)\n",
    "        \n",
    "        # Backtrack\n",
    "        best_path = np.zeros(n_obs, dtype=int)\n",
    "        best_path[-1] = np.argmax(V[:, -1])\n",
    "        for t in range(n_obs-2, q-2, -1):\n",
    "            best_path[t] = path[best_path[t+1], t+1]\n",
    "        \n",
    "        segmentations.append(best_path)\n",
    "    \n",
    "    return segmentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66f10d8f-e186-4119-92e9-9ec64367e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state_probabilities_multi(samples, sequences, original_sequences, window_size=5, sigma=2):\n",
    "    r_max = max(s[0] for s in samples)\n",
    "    n_sequences = len(sequences)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_sequences, 1, figsize=(15, 4*n_sequences), sharex=True)\n",
    "    fig.suptitle('Posterior State Probabilities', fontsize=16)\n",
    "    \n",
    "    for seq_idx, (sequence, original_sequence) in enumerate(zip(sequences, original_sequences)):\n",
    "        ax = axes[seq_idx] if n_sequences > 1 else axes\n",
    "        n_obs = len(sequence)\n",
    "        avg_probs = np.zeros((r_max, n_obs))\n",
    "        \n",
    "        for r, q, Lambda, P, all_posterior_probs, _ in samples:\n",
    "            posterior_probs = all_posterior_probs[seq_idx]\n",
    "            avg_probs[:r, :] += posterior_probs\n",
    "        \n",
    "        avg_probs /= len(samples)\n",
    "        \n",
    "        # Apply Gaussian smoothing\n",
    "        smoothed_probs = np.zeros_like(avg_probs)\n",
    "        for i in range(r_max):\n",
    "            smoothed_probs[i, :] = gaussian_filter1d(avg_probs[i, :], sigma=sigma, mode='nearest')\n",
    "        \n",
    "        # Plot smoothed probabilities\n",
    "        x = np.arange(n_obs)\n",
    "        for i in range(r_max):\n",
    "            ax.plot(x, smoothed_probs[i, :], '-', label=f'State {i+1}', alpha=0.7)\n",
    "            ax.fill_between(x, 0, smoothed_probs[i, :], alpha=0.2)\n",
    "        \n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_ylabel(f'Sequence {seq_idx + 1}')\n",
    "        ax.set_yticks([0, 0.5, 1])\n",
    "        \n",
    "        # Add sequence at the bottom of each subplot\n",
    "        for j, base in enumerate(original_sequence):\n",
    "            ax.text(j, -0.15, base, ha='center', va='center', fontsize=8)\n",
    "        \n",
    "        if seq_idx == 0:\n",
    "            ax.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "    \n",
    "    axes[-1].set_xlabel('Position in Sequence')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a235b87-39a4-4a71-a557-4137e0905cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "\n",
    "trxps = [x for x,y in ensembl_trx.items() if y['biotype'] == 'protein_coding'][:N]\n",
    "\n",
    "sequences = [x['sequence'] for x in ensembl_trx.values() if x['biotype'] == 'protein_coding'][:N]\n",
    "#sequences = ''.join(sequences)\n",
    "\n",
    "targets = [x['target'] for x in ensembl_trx.values() if x['biotype'] == 'protein_coding'][:N]\n",
    "#targets = np.concatenate(targets)\n",
    "\n",
    "# Constants\n",
    "MAX_STATES = 2  # r_max\n",
    "MAX_ORDER = 2    # q_max\n",
    "\n",
    "n_iter = 500  # Number of iterations after burn-in\n",
    "n_burn_in = 100  # Number of burn-in iterations\n",
    "thin = 2  # Store every 10th sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c98689a-b1bd-4e0c-b0f5-205e133cf886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/600 [00:00<?, ?it/s]/tmp/ipykernel_6078/2296006809.py:49: RuntimeWarning: divide by zero encountered in log\n",
      "  total_log_likelihood += np.sum(np.log(scale))\n",
      "  2%|█▍                                                                              | 11/600 [01:24<1:15:32,  7.69s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sequences_indices \u001b[38;5;241m=\u001b[39m [sequence_to_indices(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences]\n\u001b[0;32m----> 3\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43mrun_mcmc_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_burn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Plot the results\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#plot_state_probabilities_multi(samples, sequences_indices, sequences)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Analyze results\u001b[39;00m\n\u001b[1;32m      9\u001b[0m r_posterior \u001b[38;5;241m=\u001b[39m [s[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m samples]\n",
      "Cell \u001b[0;32mIn[5], line 140\u001b[0m, in \u001b[0;36mrun_mcmc_multi\u001b[0;34m(sequences, n_iter, n_burn_in, thin)\u001b[0m\n\u001b[1;32m    137\u001b[0m samples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_iter \u001b[38;5;241m+\u001b[39m n_burn_in)):\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# Update q and P\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     q, P \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_q_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# Update Lambda\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(r):\n",
      "Cell \u001b[0;32mIn[5], line 90\u001b[0m, in \u001b[0;36mupdate_q_multi\u001b[0;34m(sequences, r, q, Lambda, P)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(MAX_ORDER \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     89\u001b[0m     new_P \u001b[38;5;241m=\u001b[39m dirichlet\u001b[38;5;241m.\u001b[39mrvs(np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(new_q\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)), size\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m---> 90\u001b[0m     log_probs[new_q], _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mforward_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_P\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_q\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m new_q \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(MAX_ORDER \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, p\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mexp(log_probs \u001b[38;5;241m-\u001b[39m logsumexp(log_probs)))\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_q \u001b[38;5;241m!=\u001b[39m q:\n",
      "Cell \u001b[0;32mIn[5], line 45\u001b[0m, in \u001b[0;36mforward_multi\u001b[0;34m(sequences, Lambda, P, q)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_states):\n\u001b[1;32m     44\u001b[0m     emission_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel_multi_index(state, (\u001b[38;5;241m4\u001b[39m,)\u001b[38;5;241m*\u001b[39m(q\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 45\u001b[0m     F[j, t] \u001b[38;5;241m=\u001b[39m P[j, emission_index] \u001b[38;5;241m*\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLambda\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m scale[t] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(F[:, t])\n\u001b[1;32m     47\u001b[0m F[:, t] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m scale[t]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2324\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2325\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:69\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapreduction\u001b[39m(obj, ufunc, method, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     70\u001b[0m     passkwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     71\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue}\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mu\u001b[38;5;241m.\u001b[39mndarray:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "sequences_indices = [sequence_to_indices(seq) for seq in sequences]\n",
    "samples = run_mcmc_multi(sequences_indices, n_iter, n_burn_in, thin)\n",
    "\n",
    "# Plot the results\n",
    "#plot_state_probabilities_multi(samples, sequences_indices, sequences)\n",
    "\n",
    "# Analyze results\n",
    "r_posterior = [s[0] for s in samples]\n",
    "q_posterior = [s[1] for s in samples]\n",
    "print(f\"Posterior mode for r: {max(set(r_posterior), key=r_posterior.count)}\")\n",
    "print(f\"Posterior mode for q: {max(set(q_posterior), key=q_posterior.count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40adcb0-579c-4a40-99f2-4561eef378d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6423a8-90d9-41dd-abef-e0d03de09c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
